{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnV5re322Wz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18fcc8f1-a644-4844-a1e8-9e4ba648e56c"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt update\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 257 kB in 1s (188 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "40 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "openjdk-8-jdk-headless is already the newest version (8u462-ga~us1-0ubuntu2~22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhYIAjti3iaf"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_chOpi85JR-O"
      },
      "source": [
        "# Creamos el Spark Context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M62onPeJR-O"
      },
      "source": [
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "DATA_PATH = \"/content/drive/MyDrive/CienciaDeDatos/TP1/data/\"\n",
        "\n",
        "rdd_orders = (\n",
        "    sqlContext.read.csv(DATA_PATH + 'orders.csv', header=True, inferSchema=True)\n",
        "    .select(\"status\", \"shipping_address\")\n",
        "    .rdd\n",
        ")\n",
        "\n",
        "rdd_customers = (\n",
        "    sqlContext.read.csv(DATA_PATH + 'customers.csv', header=True, inferSchema=True)\n",
        "    .select(\"customer_id\", \"first_name\", \"postal_code\")\n",
        "    .rdd\n",
        ")\n",
        "\n",
        "TOP_CPS_SHOWED = 5\n",
        "TOP_NAMES_SHOWED = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeI_JwdEgI_Y",
        "outputId": "8d484a8e-7240-4547-c4d2-8f1c186009c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) ¿Cuáles son los 5 códigos postales más comunes para las órdenes con estado ‘Refunded’? ¿Y cuál es el nombre más frecuente entre los clientes de esas direcciones?\n",
        "\n",
        "### Hipótesis Tomadas:\n",
        "Se consideró que el código postal (CP) se extrae del shipping_address como el último espacio numérico (p.ej., en “3123 Alan Extension Port Andrea, MA 26926” el CP es 26926)."
      ],
      "metadata": {
        "id": "o1NhZT8gGmYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0GQ7o_BgBuv",
        "outputId": "1173f557-d1f0-497f-c3b4-6f12627e216a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('70696', 6), ('47612', 5), ('11954', 5), ('83755', 5), ('59883', 5)]\n"
          ]
        }
      ],
      "source": [
        "def get_cp(address):\n",
        "    try:\n",
        "        cp = address.strip().split()[-1].lower().strip()\n",
        "        if cp and cp.isdigit():\n",
        "            return cp\n",
        "        else:\n",
        "            return None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "rdd_refunded = rdd_orders.filter(\n",
        "    lambda row: row[\"status\"] is not None\n",
        "    and row[\"shipping_address\"] is not None\n",
        "    and row[\"status\"].strip().lower() == \"refunded\"\n",
        ")\n",
        "\n",
        "rdd_refunded_cps = rdd_refunded.map(lambda row: (\n",
        "    get_cp(row[\"shipping_address\"]),\n",
        "    1\n",
        ")).filter(lambda row: row[0] is not None)\n",
        "\n",
        "cps_apparitions = rdd_refunded_cps.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "top_cps = cps_apparitions.takeOrdered(TOP_CPS_SHOWED, key=lambda x: -x[1])\n",
        "\n",
        "print(top_cps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_top_cps = sc.parallelize(top_cps)\n",
        "\n",
        "rdd_customers_by_cp = (\n",
        "  rdd_customers\n",
        "    .filter(lambda row: row[\"postal_code\"] is not None and row[\"first_name\"] is not None)\n",
        "    .map(lambda row: (str(row[\"postal_code\"]).lower().strip(),\n",
        "                      row[\"first_name\"].lower().strip()))\n",
        ")\n",
        "\n",
        "print(\"Clientes totales:\", rdd_customers_by_cp.count())\n",
        "\n",
        "customers_top_refunded_cps = rdd_customers_by_cp.join(rdd_top_cps)\n",
        "\n",
        "print(\"Clientes en top CPs:\", customers_top_refunded_cps.count())\n",
        "\n",
        "name_apparitions = (\n",
        "    customers_top_refunded_cps\n",
        "    .map(lambda x: (x[1][0], 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")\n",
        "\n",
        "top_names = name_apparitions.takeOrdered(TOP_NAMES_SHOWED, key=lambda x: -x[1])\n",
        "\n",
        "print(top_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cL9AbH6n2B8",
        "outputId": "2571307e-889e-41a6-cbfd-3692d2884c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clientes totales: 399773\n",
            "Clientes en top CPs: 14\n",
            "[('kathy', 1), ('raymond', 1), ('diana', 1), ('dominique', 1), ('judith', 1), ('miranda', 1), ('jeffrey', 1), ('undefined', 1), ('shelly', 1), ('frank', 1), ('johnathan', 1), ('rhonda', 1), ('linda', 1), ('danielle', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusiones:\n",
        "\n",
        "Esta vez no hubo nombres más frecuentes. Aunque estos resultados son consistentes con los obtenidos en el primer trabajo, al tratarse de un pipeline que paraleliza el procesamiento y como hay muchos CPs con 5 órdenes, los seleccionados esta vez fueron distintos. Por lo tanto no apareció un nombre para estas direcciones más de una vez. Solamente 14 clientes se encontraron en estas direcciones, todos de nombres distintos. Entre ellos: Kathy, Raymond y Diana.\n",
        "\n",
        "Comentarios: La dispersión de CPs encontrada fue altísima. El CP más encontrado se repitió solo 6 veces. Debido a esto, el TOP de nombres fue muy pequeño.\n",
        "Si se quisiera robustecer el análisis, se podría ampliar la ventana (Top 10–20 CP).\n",
        "Saco la misma conclusión. Se extrae que, en el marco analizado, no se realizaron muchos reembolsos para un mismo lugar. Me atrevería a decir que debido a esto, parece que el sistema de compras/envío funciona bien y nadie abusa de los reembolsos, sino aparecería un nombre muchas veces.\n"
      ],
      "metadata": {
        "id": "eforvp_gGoDe"
      }
    }
  ]
}